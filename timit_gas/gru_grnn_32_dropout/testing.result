=============================================================
                    Training Config Info.                    
=============================================================
Dir                            gru_grnn_32_dropout
Model                          gru_autoencoder
Model_loc                      models/my_model
Hidden_neuron_num              64
RNN_cell_num                   32
RNN_type                       gru
Learning_rate                  0.0008
Dropout_keep_prob              0.3
Zoneout_keep_prob              1.0
Noise_magnitude                0.0
Batch_size                     60
Max_epoch                      60

=============================================================
                  Decode config info.                        
=============================================================
Dir                            gru_grnn_32_dropout
Batch_size                     25
Model_loc                      models/my_model
Tolerance_window               2
=============================================================
                      Loading data                          
=============================================================
feature dim: 39
utt_num: 1680
=============================================================
                      Set up models.                         
=============================================================

=============================================================
                      Start Decoding                         
=============================================================
Progress: 25/1680 Precision:0.7647, Recall:0.8571Progress: 50/1680 Precision:0.3971, Recall:0.8148Progress: 75/1680 Precision:0.7143, Recall:0.7317Progress: 100/1680 Precision:0.8095, Recall:0.9167Progress: 125/1680 Precision:0.5833, Recall:0.7805Progress: 150/1680 Precision:0.8293, Recall:0.9143Progress: 175/1680 Precision:0.8085, Recall:0.8718Progress: 200/1680 Precision:0.8431, Recall:0.8261Progress: 225/1680 Precision:0.8293, Recall:0.8095Progress: 250/1680 Precision:0.8333, Recall:0.7812Progress: 275/1680 Precision:0.7407, Recall:0.9024Progress: 300/1680 Precision:0.7451, Recall:0.8372Progress: 325/1680 Precision:0.7500, Recall:0.7073Progress: 350/1680 Precision:0.7143, Recall:0.6667Progress: 375/1680 Precision:0.7736, Recall:0.8250Progress: 400/1680 Precision:0.8000, Recall:0.7632Progress: 425/1680 Precision:0.8298, Recall:0.8095Progress: 450/1680 Precision:0.7000, Recall:0.9000Progress: 475/1680 Precision:0.7778, Recall:0.8293Progress: 500/1680 Precision:0.5882, Recall:0.7727Progress: 525/1680 Precision:0.6111, Recall:0.7805Progress: 550/1680 Precision:0.8043, Recall:0.8421Progress: 575/1680 Precision:0.7200, Recall:0.7949Progress: 600/1680 Precision:0.5870, Recall:0.9167Progress: 625/1680 Precision:0.6667, Recall:0.8095Progress: 650/1680 Precision:0.7500, Recall:0.8387Progress: 675/1680 Precision:0.5152, Recall:0.7778Progress: 700/1680 Precision:0.5882, Recall:0.7826Progress: 725/1680 Precision:0.6852, Recall:0.8250Progress: 750/1680 Precision:0.8537, Recall:0.9062Progress: 775/1680 Precision:0.7200, Recall:0.8205Progress: 800/1680 Precision:0.7742, Recall:0.8636Progress: 825/1680 Precision:0.8182, Recall:0.7895Progress: 850/1680 Precision:0.6415, Recall:0.7692Progress: 875/1680 Precision:0.7609, Recall:0.8108Progress: 900/1680 Precision:0.7200, Recall:0.6957Progress: 925/1680 Precision:0.8049, Recall:0.7838Progress: 950/1680 Precision:0.7500, Recall:0.9643Progress: 975/1680 Precision:0.6250, Recall:0.7317Progress: 1000/1680 Precision:0.8387, Recall:0.8621Progress: 1025/1680 Precision:0.7333, Recall:0.7500Progress: 1050/1680 Precision:0.4545, Recall:0.7222Progress: 1075/1680 Precision:0.7442, Recall:0.8571Progress: 1100/1680 Precision:0.7818, Recall:0.8367Progress: 1125/1680 Precision:0.7234, Recall:0.8205Progress: 1150/1680 Precision:0.6579, Recall:0.8077Progress: 1175/1680 Precision:0.8140, Recall:0.8205Progress: 1200/1680 Precision:0.6250, Recall:0.6957Progress: 1225/1680 Precision:0.6444, Recall:0.7805Progress: 1250/1680 Precision:0.7429, Recall:0.8621Progress: 1275/1680 Precision:0.8250, Recall:0.7561Progress: 1300/1680 Precision:0.8182, Recall:0.8485Progress: 1325/1680 Precision:0.8696, Recall:0.8293Progress: 1350/1680 Precision:0.7111, Recall:0.8919Progress: 1375/1680 Precision:0.7083, Recall:0.8684Progress: 1400/1680 Precision:0.8065, Recall:0.7419Progress: 1425/1680 Precision:0.7391, Recall:0.8684Progress: 1450/1680 Precision:0.6250, Recall:0.6957Progress: 1475/1680 Precision:0.7447, Recall:0.8250Progress: 1500/1680 Precision:0.9677, Recall:0.9091Progress: 1525/1680 Precision:0.7234, Recall:0.7632Progress: 1550/1680 Precision:0.6667, Recall:0.8077Progress: 1575/1680 Precision:0.7241, Recall:0.8780Progress: 1600/1680 Precision:0.8108, Recall:0.9032Progress: 1625/1680 Precision:0.7907, Recall:0.8500Progress: 1650/1680 Precision:0.8250, Recall:0.9375Progress: 1675/1680 Precision:0.8718, Recall:0.8378Progress: 1680/1680 Precision:0.8298, Recall:0.8936
thresh precision recall f_score r_val
0.0500 93.9193 21.1612 34.5401 44.2505
0.0300 91.9170 44.2718 59.7601 60.5693
0.0100 78.9923 78.6696 78.8306 81.9359
0.0090 77.4464 80.6714 79.0260 81.8080
0.0080 75.8324 82.6373 79.0888 80.9165
0.0075 75.0480 83.6743 79.1267 80.1810
0.0070 74.1650 84.7167 79.0904 79.1261
0.0065 73.2339 85.7390 78.9946 77.7971
0.0060 72.3068 86.7559 78.8751 76.2657
0.0055 71.3620 87.8631 78.7575 74.4763
0.0050 70.3112 88.8406 78.4972 72.4278
0.0045 69.2961 89.8760 78.2556 70.2324
0.0040 68.1732 90.8435 77.8924 67.7599
0.0030 65.9477 92.8159 77.1083 62.3706
0.0020 63.6564 94.4827 76.0650 56.5584
0.0010 61.4673 95.9285 74.9253 50.6328

The best r_val is: 81.9359
