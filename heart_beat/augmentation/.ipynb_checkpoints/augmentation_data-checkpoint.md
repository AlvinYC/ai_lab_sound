# Description
refernce by kaggle, paper and other idea 
we divide the heart sound augmentation into two major categories, 
  * <b>signal aspect</b>: feature is generated by programming
  * <b>knowledge aspect</b>: feature is <font color=red>not</font> generated by programming
    
each category have correspoding detail augmenation method, please check the following list

# Summary
* signal aspect
  - [x] 1.<font color=blue>[kaggle]</font> white noise
  - [ ] 2.<font color=green>[paper]</font> Dither <font color=gray>white noise imply this behavior</font>
  - [x] 3.<font color=blue>[kaggle]</font> Stretch (± second)
  - [ ] 4.<font color=blue>[kaggle]</font> Frequency (± hz) <font color=gray>stretch imply frequency adjust</font>
  - [ ] 5.<font color=green>[paper]</font> Pitch (± semitone) <font color=gray>period observation not clear in heart sound</font>
  - [ ] 6.<font color=blue>[kaggle]</font> Shift <font color=gray> i think its useless for model training</font>
  - [x] 7.Silence
  - [x] 8.<font color=blue>[kaggle]</font> Volume
* knowledge aspect (mix some ohter voice)
  - [x] 1.<font color=green>[paper]</font> mix humand speech (dataset)
  - [ ] 2.mix environment voice such as office 
    - [ ] office voice <font color=gray>(hard to get rich variance)</font>
    - [ ] home voice <font color=gray>(hard to get rich variance)</font>
  - [x] 3.mix breath (lung) voice

# Audio example for each augmentation method
we use the following file as based line wave, which contain 8 second normal heart beat 
```python
physionet/training/training-b/b0038.wav
```
this wave will cobime with augmenation method into a new wave in the following session

## Signal aspect - 1.white noise

![orignal_jpg](https://drive.google.com/uc?id=1UtO_udriuksasivUoXttlIWoPNHk2QX0)

```python

```
